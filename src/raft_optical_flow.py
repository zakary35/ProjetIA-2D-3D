import torch
import torch.nn as nn
import numpy as np
import cv2
import os
import argparse
from typing import Optional, Tuple, Union

# Gestion des imports relatifs (Le dossier 'raft' doit √™tre pr√©sent)
try:
    from .raft.raft import RAFT
    from .raft.utils.utils import InputPadder
except ImportError:
    # Fallback si lanc√© depuis la racine sans structure de package
    import sys
    sys.path.append('src/raft') # Ajustez selon votre structure
    try:
        from raft.raft import RAFT
        from raft.utils.utils import InputPadder
    except ImportError:
        raise ImportError("‚ùå Le module 'raft' (code source officiel) est introuvable. "
                          "Veuillez cloner le repo RAFT dans le dossier src/.")

class RAFTFlowEngine:
    """
    Moteur d'estimation de Flux Optique bas√© sur RAFT (Recurrent All-Pairs Field Transforms).
    Optimis√© pour l'inf√©rence vid√©o avec compilation JIT et gestion m√©moire.
    
    Pattern Singleton : Assure une seule instance du mod√®le en m√©moire.
    """
    _instance: Optional['RAFTFlowEngine'] = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(RAFTFlowEngine, cls).__new__(cls)
        return cls._instance

    def __init__(self, 
                 checkpoint_path: str = "checkpoints/raft/raft-things.pth", 
                 small: bool = False, 
                 device: str = None,
                 iters: int = 20):
        """
        Initialise le moteur RAFT.

        Args:
            checkpoint_path (str): Chemin vers le mod√®le pr√©-entra√Æn√© (.pth).
            small (bool): Si True, utilise RAFT-Small (plus rapide, moins pr√©cis).
            device (str): 'cuda' ou 'cpu'.
            iters (int): Nombre d'it√©rations du GRU interne (D√©faut=20). 
                         R√©duire √† 10-12 acc√©l√®re massivement sans trop perdre en qualit√©.
        """
        # √âvite la r√©-initialisation si l'instance existe d√©j√† (Singleton)
        if hasattr(self, 'initialized'): return
        
        # 1. Configuration du Device
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
            
        self.iters = iters
        self.small = small
        
        print(f"üöÄ [RAFT] Initialisation sur : {str(self.device).upper()}")

        # 2. Cr√©ation de la configuration (Sans EasyDict)
        self.args = argparse.Namespace(
            small=small,
            mixed_precision=True, # Active le FP16 pour les calculs internes
            alternate_corr=False
        )
        
        # 3. Chargement de l'architecture
        try:
            self.model = RAFT(self.args)
        except Exception as e:
            raise RuntimeError(f"‚ùå [RAFT] Erreur lors de l'instanciation du mod√®le : {e}")
        
        # 4. Chargement des poids
        self._load_checkpoint(checkpoint_path)
        
        self.model.to(self.device).eval()
        
        # 5. Optimisation : Torch Compile (PyTorch 2.x+)
        # Note : DataParallel a √©t√© retir√© car inutile pour un batch size de 1 (Vid√©o Stream)
        if torch.cuda.is_available():
            try:
                # 'reduce-overhead' est id√©al pour les petites boucles d'inf√©rence r√©p√©t√©es
                self.model = torch.compile(self.model, mode="reduce-overhead")
                print("‚ö° [RAFT] Compilation JIT activ√©e (PyTorch 2.0+).")
            except Exception:
                print("‚ÑπÔ∏è [RAFT] Compilation √©chou√©e ou indisponible. Passage en mode standard.")
            
        self.initialized = True

    def _load_checkpoint(self, path: str):
        """
        Charge les poids de mani√®re robuste (CPU -> GPU).
        G√®re le pr√©fixe 'module.' si le checkpoint vient d'un entra√Ænement Multi-GPU.
        """
        if not os.path.exists(path):
            raise FileNotFoundError(f"‚ùå [RAFT] Checkpoint introuvable : {path}")
            
        # Chargement sur CPU pour √©viter les OOM imm√©diats
        state_dict = torch.load(path, map_location='cpu')
        
        # Nettoyage des cl√©s (retrait de 'module.' si pr√©sent)
        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        
        try:
            self.model.load_state_dict(new_state_dict)
        except RuntimeError as e:
            print(f"‚ö†Ô∏è [RAFT] Attention : Mismatch de cl√©s. V√©rifiez que 'small={self.small}' correspond au checkpoint.")
            raise e

    def _preprocess(self, img: np.ndarray) -> torch.Tensor:
        """
        Pr√©traitement : BGR [H, W, 3] -> RGB Normalis√© [1, 3, H, W] sur GPU.
        """
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        tensor = torch.from_numpy(img_rgb).permute(2, 0, 1).float()
        return tensor.unsqueeze(0).to(self.device)

    @torch.no_grad()
    def compute_flow(self, img_prev: np.ndarray, img_curr: np.ndarray) -> np.ndarray:
        """
        Calcule le flux optique dense entre deux frames.

        Args:
            img_prev (np.ndarray): Image √† t-1 [H, W, 3] (BGR).
            img_curr (np.ndarray): Image √† t [H, W, 3] (BGR).

        Returns:
            np.ndarray: Champ de vecteurs [H, W, 2] (Float32).
                        Canal 0 : D√©placement Horizontal (dx).
                        Canal 1 : D√©placement Vertical (dy).
        """
        # Validation des dimensions
        if img_prev.shape != img_curr.shape:
            raise ValueError(f"Dimensions incompatibles : {img_prev.shape} vs {img_curr.shape}")

        img1 = self._preprocess(img_prev)
        img2 = self._preprocess(img_curr)

        # Padding : RAFT n√©cessite des dimensions divisibles par 8
        padder = InputPadder(img1.shape)
        img1_pad, img2_pad = padder.pad(img1, img2)

        # Inf√©rence avec pr√©cision mixte (Automatic Mixed Precision)
        # Acc√©l√®re significativement sur les GPU modernes (T4, A100, RTX)
        with torch.amp.autocast(device_type=self.device.type, enabled=True):
            # RAFT retourne une liste de flux (du plus grossier au plus fin)
            # On prend le dernier √©l√©ment ([-1]) qui est le plus raffin√©
            flow_low, flow_up = self.model(img1_pad, img2_pad, iters=self.iters, test_mode=True)
        
        # Post-traitement : Unpad et retour sur CPU
        # flow_up est [1, 2, H, W]
        flow_tensor = padder.unpad(flow_up)[0] 
        flow_numpy = flow_tensor.permute(1, 2, 0).cpu().numpy() # [H, W, 2]
        
        return flow_numpy